{
	"ReplicaConfig": {
		"model_name": "meta-llama/Llama-2-7b-hf",
		"memory_margin_fraction": 0.1,
		"num_pipeline_stages": 1,
		"tensor_parallel_size": 1,
		"device": "a30",
		"network_device": "a100_pairwise_nvlink"
	},
	"vllm_scheduler_config": {
		"max_tokens_in_batch": 4086
	},
	"target_metric": "min_latency"
}